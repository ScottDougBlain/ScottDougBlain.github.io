<section id="experience" class="model-behavior-section">
        <div class="container">
            <h2 class="section-title">Model Behavior Experience</h2>
            <p class="section-subtitle">Translating cognitive science into practical AI alignment solutions</p>
            
            <div class="experience-highlights">
                <div class="highlight-card brief">
                    <div class="highlight-header">
                        <span class="highlight-icon">üß†</span>
                        <h3>Metacognitive Hallucination Framework</h3>
                        <span class="impact-badge">71% Reduction</span>
                    </div>
                    <div class="highlight-content">
                        <p>Psychology-informed framework that demonstrated a 71% reduction in hallucination rates by applying CBT principles to LLM prompting.</p>
                    </div>
                </div>

                <div class="highlight-card brief">
                    <div class="highlight-header">
                        <span class="highlight-icon">üé≠</span>
                        <h3>LLM Mentalizing Framework</h3>
                    </div>
                    <div class="highlight-content">
                        <p>Comprehensive evaluation suite for AI theory of mind capabilities‚Äîrelevant for the detection of situational awareness and deceptive capabilities.</p>
                    </div>
                </div>

                <div class="highlight-card brief">
                    <div class="highlight-header">
                        <span class="highlight-icon">‚öôÔ∏è</span>
                        <h3>Dynamic LLM Personality Systems</h3>
                    </div>
                    <div class="highlight-content">
                        <p>Currently building adaptive AI systems based on personality psychology principles, enabling predictable behavior control and personalized alignment frameworks.</p>
                    </div>
                </div>

            </div>

            <div class="industry-experience">
                <h3>Professional Experience & Development</h3>
                <div class="experience-section">
                    <h4>Industry Experience</h4>
                    <div class="experience-item featured">
                        <div class="experience-header">
                            <h5>Senior Data Quality Specialist (Freelance)</h5>
                            <span class="experience-period">2024 ‚Äì Present</span>
                        </div>
                        <div class="experience-company">Cohere, San Francisco, CA | Snorkel, Redwood City, CA</div>
                        <p>Evaluate large language model outputs for safety and alignment, focusing on identifying failure modes and improving reliability. Develop systematic approaches to assess model behavior and create evaluation frameworks based on cognitive science principles.</p>
                        <ul class="experience-achievements">
                            <li>Essential contributor of qualitative model output evaluations enabling rollout of Cohere's Command A frontier model</li>
                            <li>Contributed 250+ benchmark items to assess model behavior across domains (e.g., social reasoning, factuality, honesty)</li>
                            <li>Apply cognitive science frameworks to evaluate model outputs and identify potential risks</li>
                            <li>Develop prompt engineering methodologies informed by psychology research</li>
                            <li>Create evaluation rubrics for assessing model behavior in multi-turn dialogues</li>
                            <li>Contribute to safety datasets and quality improvement initiatives</li>
                        </ul>
                    </div>
                </div>
                
                <div class="training-section">
                    <h4>AI Safety & Ethics Training</h4>
                    <div class="training-grid">
                        <div class="training-item">
                            <h5>üåç Global Challenges Project (2025)</h5>
                            <p>Emerging challenges in AI safety and biosecurity and interdisciplinary approaches to existential risks</p>
                        </div>
                        <div class="training-item">
                            <h5>ü§ñ Ethics of AI | University of Helsinki (2025)</h5>
                            <p>Ethical AI development/use and applying frameworks from moral philosophy to questions related to contemporary AI</p>
                        </div>
                        <div class="training-item">
                            <h5>üéì AI Safety Fundamentals | BlueDot Impact (2024)</h5>
                            <p>Technical alignment studies, including inner/outer alignment, interpretability, and safety frameworks</p>
                        </div>
                    </div>
                </div>
                
            </div>
        </div>
    </section>