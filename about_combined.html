<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>About - Scott Blain</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <nav>
            <ul>
                <li><a href="index.html">Home</a></li>
                <li><a href="about.html" class="active">About</a></li>
                <li><a href="research.html">Research</a></li>
                <li><a href="publications.html">Publications</a></li>
                <li><a href="contact.html">Contact</a></li>
            </ul>
        </nav>
    </header>

    <main>
        <!-- Why Psychology for AI Safety Section -->
        <section class="why-psychology-section">
            <div class="container">
                <h2 class="section-title">Why Psychology for AI Safety?</h2>
                <p class="section-subtitle">Understanding human minds is essential for building aligned AI systems</p>
                
                <div class="psychology-grid">
                    <div class="psychology-card">
                        <div class="card-icon">üß†</div>
                        <h3>Understanding Model 'Cognition'</h3>
                        <p>Humans exhibit cognitive biases and predictable failure modes; AI systems similarly display such patterns. My investigations into human apophenia (false pattern detection) inform targeted strategies to mitigate AI hallucinations, ensuring systems verify rather than merely detect patterns.</p>
                    </div>
                    
                    <div class="psychology-card">
                        <div class="card-icon">ü§ù</div>
                        <h3>Human-Compatible Design</h3>
                        <p>AI systems must interface naturally with human psychology. However, with increased social cognitive abilities comes increased risk of manipulation and deception. My research on this phenomenon in humans provides crucial insights for ensuring AI systems can cooperate effectively while avoiding socially disruptive patterns.</p>
                    </div>
                    
                    <div class="psychology-card">
                        <div class="card-icon">‚öñÔ∏è</div>
                        <h3>Rigorous Trait Evaluation</h3>
                        <p>Effectively assessing AI behaviors like honesty, helpfulness, and harmlessness requires nuanced psychometric frameworks. My expertise in personality and behavioral assessment provides the tools needed for evaluating these complex traits beyond superficial metrics.</p>
                    </div>
                </div>
                
                <div class="psychology-statement">
                    <h3>Vision for Model Behavior</h3>
                    <p>Where others see only technical hurdles, I identify cognitive analogies informed by decades of psychological research. This unique vantage point is indispensable for creating AI systems aligned deeply and reliably with human values.</p>
                </div>
            </div>
        </section>

        <!-- Model Behavior Experience Section -->
        <section id="experience" class="model-behavior-section">
            <div class="container">
                <h2 class="section-title">Model Behavior Experience</h2>
                <p class="section-subtitle">Translating cognitive science into practical AI alignment solutions</p>
                
                <div class="experience-highlights">
                    <div class="highlight-card brief">
                        <div class="highlight-header">
                            <span class="highlight-icon">üß†</span>
                            <h3>Metacognitive Hallucination Framework</h3>
                            <span class="impact-badge">71% Reduction</span>
                        </div>
                        <div class="highlight-content">
                            <p>Psychology-informed framework that demonstrated a 71% reduction in hallucination rates by applying CBT principles to LLM prompting.</p>
                        </div>
                    </div>

                    <div class="highlight-card brief">
                        <div class="highlight-header">
                            <span class="highlight-icon">üé≠</span>
                            <h3>LLM Mentalizing Framework</h3>
                        </div>
                        <div class="highlight-content">
                            <p>Comprehensive evaluation suite for AI theory of mind capabilities‚Äîrelevant for the detection of situational awareness and deceptive capabilities.</p>
                        </div>
                    </div>

                    <div class="highlight-card brief">
                        <div class="highlight-header">
                            <span class="highlight-icon">‚öôÔ∏è</span>
                            <h3>Dynamic LLM Personality Systems</h3>
                        </div>
                        <div class="highlight-content">
                            <p>Currently building adaptive AI systems based on personality psychology principles, enabling predictable behavior control and personalized alignment frameworks.</p>
                        </div>
                    </div>

                </div>

                <div class="industry-experience">
                    <h3>Professional Experience & Development</h3>
                    <div class="experience-section">
                        <h4>Industry Experience</h4>
                        <div class="experience-item featured">
                            <div class="experience-header">
                                <h5>Senior Data Quality Specialist (Freelance)</h5>
                                <span class="experience-period">2024 ‚Äì Present</span>
                            </div>
                            <div class="experience-company">Cohere, San Francisco, CA | Snorkel, Redwood City, CA</div>
                            <p>Evaluate large language model outputs for safety and alignment, focusing on identifying failure modes and improving reliability. Develop systematic approaches to assess model behavior and create evaluation frameworks based on cognitive science principles.</p>
                            <ul class="experience-achievements">
                                <li>Essential contributor of qualitative model output evaluations enabling rollout of Cohere's Command A frontier model</li>
                                <li>Contributed 250+ benchmark items to assess model behavior across domains (e.g., social reasoning, factuality, honesty)</li>
                                <li>Apply cognitive science frameworks to evaluate model outputs and identify potential risks</li>
                                <li>Develop prompt engineering methodologies informed by psychology research</li>
                                <li>Create evaluation rubrics for assessing model behavior in multi-turn dialogues</li>
                                <li>Contribute to safety datasets and quality improvement initiatives</li>
                            </ul>
                        </div>
                    </div>
                    
                    <div class="training-section">
                        <h4>AI Safety & Ethics Training</h4>
                        <div class="training-grid">
                            <div class="training-item">
                                <h5>üåç Global Challenges Project (2025)</h5>
                                <p>Emerging challenges in AI safety and biosecurity and interdisciplinary approaches to existential risks</p>
                            </div>
                            <div class="training-item">
                                <h5>ü§ñ Ethics of AI | University of Helsinki (2025)</h5>
                                <p>Ethical AI development/use and applying frameworks from moral philosophy to questions related to contemporary AI</p>
                            </div>
                            <div class="training-item">
                                <h5>üéì AI Safety Fundamentals | BlueDot Impact (2024)</h5>
                                <p>Technical alignment studies, including inner/outer alignment, interpretability, and safety frameworks</p>
                            </div>
                        </div>
                    </div>
                    
                </div>
            </div>
        </section>

        <!-- Future Directions Section -->
        <section class="future-directions-section">
            <div class="container">
                <h3>Next Research Directions</h3>
                <div class="research-ideas">
                    <div class="idea-card">
                        <h4>üîç Mechanistic Interpretability</h4>
                        <p>Using neuroscience methods to understand how AI systems form and retrieve false memories and hallucinations.</p>
                    </div>
                    <div class="idea-card">
                        <h4>üìä Hierarchical Alignment Frameworks</h4>
                        <p>Developing multi-level alignment strategies that address both capability and behavioral alignment simultaneously.</p>
                    </div>
                </div>
            </div>
        </section>

        <!-- Career Focus Section -->
        <section class="career-focus-section">
            <div class="container">
                <div class="career-statement">
                    <div class="career-icon">üéØ</div>
                    <h3>Current Mission: Seeking Impact</h3>
                    <p>I seek roles at the intersection of model behavior research, AI safety, and human-AI interaction design. My expertise in cognitive science positions me uniquely to develop robust, human-centered AI systems. My goal is to ensure AI not only performs powerfully but remains fundamentally aligned with human values and cognition.</p>
                    <div class="career-keywords">
                        <span class="keyword">Model Behavior Architect</span>
                        <span class="keyword">AI Safety Researcher</span>
                        <span class="keyword">HCI Specialist</span>
                    </div>
                    <div class="mission-cta">
                        <a href="Scott_Blain_RESUME_2025.docx" class="btn btn-primary" download>View Resume</a>
                    </div>
                </div>
            </div>
        </section>
    </main>

    <footer>
        <div class="container">
            <p>&copy; 2025 Scott Blain. All rights reserved.</p>
        </div>
    </footer>

    <script src="scripts.js"></script>
</body>
</html>